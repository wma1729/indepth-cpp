# Data Types

## Integer Types

C++ offers various integer types. These vary based on their size, sign, and purpose. The following output is generated by [integer](integer.cpp) on 64-bit Linux and 64-bit Windows system.

x86_64 Linux
```
                Type    Size                 Minimum                 Maximum      Signed
                bool       1                       0                       1       false
                char       1                    -128                     127        true
         signed char       1                    -128                     127        true
       unsigned char       1                       0                     255       false
               short       2                  -32768                   32767        true
      unsigned short       2                       0                   65535       false
                 int       4             -2147483648              2147483647        true
        unsigned int       4                       0              4294967295       false
              signed       4             -2147483648              2147483647        true
            unsigned       4                       0              4294967295       false
                long       8    -9223372036854775808     9223372036854775807        true
       unsigned long       8                       0    18446744073709551615       false
           long long       8    -9223372036854775808     9223372036854775807        true
  unsigned long long       8                       0    18446744073709551615       false
```

x86_64 Windows 10
```
                Type    Size                 Minimum                 Maximum      Signed
                bool       1                       0                       1       false
                char       1                    -128                     127        true
         signed char       1                    -128                     127        true
       unsigned char       1                       0                     255       false
               short       2                  -32768                   32767        true
      unsigned short       2                       0                   65535       false
                 int       4             -2147483648              2147483647        true
        unsigned int       4                       0              4294967295       false
              signed       4             -2147483648              2147483647        true
            unsigned       4                       0              4294967295       false
                long       4             -2147483648              2147483647        true
       unsigned long       4                       0              4294967295       false
           long long       8    -9223372036854775808     9223372036854775807        true
  unsigned long long       8                       0    18446744073709551615       false
```

A few things stand out from these tables:
- `char`, `signed char`, and `unsigned char` are all treated as separate data types. Is the **char** signed or unsigned? It depends on the platform. On both of the systems above, char is signed. But there are platforms out there where char could be signed.
- `short`, `int`, and `long` are always signed. `char` is the odd one out.
- Both `signed` and `unsigned`, without further qualifications, resolve to 4-byte integer type.
- On Windows, `long` is 4-bytes even on 64-bit platform.

### Negative Number Storage
Negative numbers are stored as 2's complement, which is 1's complement + 1.
Number | Binary Representation | 1's complement | 2's complement
-------|-----------------------|----------------|---------------
0      | 0000 0000             | 1111 1111      | 0000 0000
1      | 0000 0001             | 1111 1110      | 1111 1111
2      | 0000 0010             | 1111 0010      | 1111 0011
126    | 0111 1110             | 1000 0001      | 1000 0010
127    | 0111 1111             | 1000 0000      | 1000 0001

### Casting
Casting up an integer number, I<sub>small</sub>, to a bigger integer data type is safe as along as I<sub>small</sub> is not negative.
```C++
short s = -1;             // s = 0xffff
unsigned int i = s;       // i = 0xffff ffff
```

This is usually not that bad as most programmers understand such nuances. Problems arise when the compiler does an auto upcast.
```C++
#include <iostream>

int
main()
{
        short           s = -1;
        unsigned int    i = 1;

        /*
         * One side of the comparison is short and the other side is unsigned int.
         * The compiler wants both the sides same. So it auto upgrades the smaller
	 * typed variable s to unsigned int.
	 * This makes s bigger than i. An easy to hide bug!
         */
        if (s > i)
                std::cout << "Surprise!!!" << std::endl;
        else
                std::cout << "Liar!" << std::endl;

        return 0;
}
```

Casting down an integer number to a smaller integer data type is dangerous and can lead to loss of information. You will see tons of code around where downcast is seen. In those cases, the programmers are usually aware of the possible values that the variables can hold.

### Shift Operators
The behavior of shift operators on negative numbers is undefined.

### When to use signed/unsigned data types.
Use unsigned types when dealing with flags/bitmaps where the values are primarily set/checked/cleared using bitwise operator. They are often very useful when programming lower level system programming like interaction with hardware device, low level protocol management, etc. especially when the extra bit can be the life-saver. For all other needs rely on signed data types.

### stdint.h/cstdint
Avoid the urge to define your own integer types like
```C++
typedef short           int16;
typedef unsigned short  uint16;
typedef int             int32;
typedef unsigned int    uint32;
```
If having the size embedded in the type name is comforting to you, look at stdint.h or its C++ sibling cstdint. Many such types are already pre-defined there.

### My 2 cents on unsignedness of size_t
Hate it! It lead to the creation of ssize_t (signed size_t).  I am aware of most arguments in favor of it. From my experience, it leads to useless type-casting and in some cases prevent natural programming flow.

## Real Types
C++ primarily offers two real types: `float` and `double`. Both are signed. There is no concept of unsigned. Some platforms offer `long double` as well.  The following output is generated by [real](real.cpp) on 64-bit Linux and 64-bit Windows system.

x86_64 Linux
```
        Type  Size         Min -ve         Min +ve         Max +ve   Radix  Digits   Min-Exp   Max-Exp  IEEE 754
       float     4    -3.40282e+38     1.17549e-38     3.40282e+38       2      24      -125       128      true
      double     8   -1.79769e+308    2.22507e-308    1.79769e+308       2      53     -1021      1024      true
 long double    16  -1.18973e+4932    3.3621e-4932   1.18973e+4932       2      64    -16381     16384      true
```

x86_64 Windows 10
```
        Type  Size         Min -ve         Min +ve         Max +ve   Radix  Digits   Min-Exp   Max-Exp  IEEE 754
       float     4    -3.40282e+38     1.17549e-38     3.40282e+38       2      24      -125       128      true
      double     8   -1.79769e+308    2.22507e-308    1.79769e+308       2      53     -1021      1024      true
 long double     8   -1.79769e+308    2.22507e-308    1.79769e+308       2      53     -1021      1024      true
```

What do we learn from these tables?
- Both Linux and Windows follow IEEE 754 format for real numbers.
- `double` is identical to `long double` on Windows.
- `double` and `long double` on Linux are different data types. The real size of `long double` is **10** as we will see.

### Intro to real number storage
Real numbers, like integers, are stored as binary.

Base | Number | Equivalent |Scientific
-----|--------|------------|----------
10   | 235.25 | 2 * 10<sup>2</sup> + 3 * 10<sup>1</sup> + 5 * 10<sup>0</sup> + 2 * 10<sup>-1</sup> + 5 * 10<sup>-2</sup> | 2.3225 * 10<sup>2</sup>
2    | 1110 1011 . 01 | 1 * 2<sup>7</sup> + 1 * 2<sup>6</sup> + 1 * 2<sup>5</sup> + 0 * 2<sup>4</sup> + 1 * 2<sup>3</sup> + 0 * 2<sup>2</sup> + 1 * 2<sup>1</sup> + 1 * 2<sup>0</sup> + 0 * 2<sup>-1</sup> + 1 * 2<sup>-2</sup> | 1.110 1011 01 * 2<sup>7</sup>

How to convert decimal real number to binary number?
```
For the whole part, 235, keep dividing the number by 2 until 0 and keep storing the remainder.
    235          Remainder

2 | 235
2 | 117          1  (MSB)
2 | 58           1    |
2 | 29           0    |
2 | 14           1    |
2 | 7            0    |
2 | 3            1    |
2 | 1            1    V
  | 0 (Stop)     1  (LSB)

For the fraction part, .25, keep multiplying by 2 until 1.0 and store the number left of the decimal point.
    .25                  Left of decimal
    
2 * .25 = 0.50           0
2 * .50 = 1.00           1
```

### Intro the IEEE 754 format 
A number is scientific notation is **m * b<sup>e</sup>** where
- **m** is called the **mantissa** or the significand
- **b** is the **base** or the radix
- **e** is the **exponent**.

A real number in IEEE 754 format is represented as:
Size | Sign Bit   | Exponent          | Mantissa         | Bias
-----|------------|-------------------|------------------|------------------
32   | 31 (1 bit) | 30 - 23 (8 bits)  | 22 - 0 (23 bits) | 127 
64   | 63 (1 bit) | 62 - 52 (11 bits) | 51 - 0 (52 bits) | 1023
80   | 79 (1 bit) | 78 - 64 (15 bits) | 63 - 0 (64 bits) | 16383

**Sign Bit:** 1 for negative number and 0 for positive number.

**Exponent:** -1 is 1111 1111 while 0 is 0000 0000. This makes comparison between two real numbers difficult. To address this, a **bias** is used. For 32-bit real number, the bias is 127 i.e. 1111 1111.

Number | Binary Value | Binary Value + Bias
-------|--------------|-------------------------
-127   | 1000 0001    | 0000 0000
-126   | 1000 0010    | 0000 0001
-125   | 1000 0011    | 0000 0010
-2     | 1111 1110    | 0111 1101
-1     | 1111 1111    | 0111 1110
0      | 0000 0000    | 0111 1111
1      | 0000 0001    | 1000 0000
2      | 0000 0010    | 1000 0001
125    | 0111 1101    | 1111 1100
126    | 0111 1110    | 1111 1101
127    | 0111 1111    | 1111 1110
128    | 1000 0000    | 1111 1111

**Mantissa:** It is usually of the form 1.bbbbbb... Because 1 is implicit, it is usually skipped from the representation and the mantissa bits are effectively 24 instead of 23, 53 instead of 52, and 65 instead of 64 for 32-bit, 64-bit, and 80-bit representations respectively.
